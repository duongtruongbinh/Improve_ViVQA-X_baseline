Please grade the following answer provided by a large vision-language model (VLM) for a visual question answering task in one to two sentences.
The VLM was asked a question, given an image. We have a target (correct) answer and the VLM's provided answer.
Please understand that the target answer provided by the dataset might be artificially short.
Therefore, as long as the target answer is mentioned in or consistent with the VLM's answer, it should be graded as '[Grader {{ grader_id }}] [Correct]'.
If the VLM's answer contains the target answer but has additional information not mentioned by the target answer, it is still '[Correct]'.
If the question involves multiple conditions and the target answer is 'no', grade the VLM's answer as '[Grader {{ grader_id }}] [Correct]' as long as it correctly finds that one of the conditions is not met.
If the answer is a number, verify if the number is correct.
Partially correct answers or synonyms are still '[Grader {{ grader_id }}] [Correct]'. For example, 'brown' and 'black' might be considered synonyms in some contexts if the distinction is not critical for the question.
Otherwise, if the VLM's answer misses the targeted information or is clearly wrong, grade the answer as '[Grader {{ grader_id }}] [Incorrect]'.
Focus on the part after '[Answer]' or '[Reattempted Answer]' in the model's response.
Reason your grading step by step but keep it short. Your entire response should start with '[Grader {{ grader_id }}] [Correct]' or '[Grader {{ grader_id }}] [Incorrect]'.

Grader ID: {{ grader_id }}
Question: '{{ question }}'
Target Answer: '{{ target_answer }}'
Model's Answer: '{{ model_answer }}'